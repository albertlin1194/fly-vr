import abc
import numpy as np
import scipy
from scipy import io
from scipy import signal
import pandas as pd
import os.path
import time
import h5py

# from audio.signal_producer import SignalProducer, SampleChunk, MixedSignal, ConstantSignal
from psychopy import visual, core, event
from psychopy.visual.windowwarp import Warper

# need code to connect to projector and set it to the correct frame rate

class VisualStim(metaclass=abc.ABCMeta):
    # class VisualStim(SignalProducer, metaclass=abc.ABCMeta):
    """
    The VisualStim class is base class meant to encapsulate common functionality and implementation details found in
    any visual stimulus. ...
    """

    # def __init__(self, sample_rate, duration, intensity=1.0, pre_silence = 0, post_silence = 0, attenuator=None,
    #              frequency=None, max_value=10.0, min_value=-10.0, next_event_callbacks=None):
    def __init__(self, calibration_file=None):
        """
        Create an audio stimulus object that encapsulates the generation of the underlying audio
        data.
        :param int sample_rate: The sample rate in Hz of the underlying audio data.
        :param int duration: The duration of the sound in milliseconds
        :param int pre_silence: The duration (in milliseconds) of silence to add to the start of the signal.
        :param int post_silence: The duration (in milliseconds) of silence to add to the end of the signal.
        :param list next_event_callbacks: A list of control functions to call whenever the generator produced by this
        class yields a value.
        """

        # Attach event next callbacks to this object, since it is a signal producer
        # super(AudioStim, self).__init__(next_event_callbacks)

        self.__win = visual.Window([1440,900],monitor='testMonitor')

        self.__warper = Warper(self.__win,
                        # warp='spherical',
                        # warp='warpfile',
                        # warpfile = "calibratedBallImage.data",
                        warpGridsize = 300,
                        eyepoint = [0.5, 0.5],
                        flipHorizontal = False,
                        flipVertical = False)

        self.__fps = 60     # fix this

        # # How many samples have been generated by calls to data_generator() iterators
        # self.num_samples_generated = 0

        # Setup a dictionary for the parameters of the stimulus. We will send this as part
        # of an event message to the next_event_callbacks
        self.event_message = {"name": type(self).__name__,
                              "calibration_file": calibration_file,"fps":self.__fps}

        # Initialize data to null
        self.__data = []


    @abc.abstractmethod
    def _generate_data(self):
        """
        Generate any internal data necessary for the stimulus, called when parameters
        are changed only. This is so we don't have to keep generating the data with every
        call to get_data. This method should be overloaded in any sub-class to generate the
        actual audio data.

        :return: The data representing the stimulus.
        :rtype: numpy.ndarray
        """

    @property
    def data(self):
        """
        Get the voltage signal data associated with this stimulus.

        :return: A 1D numpy.ndarray of data that can be passed directly to the DAQ.
        :rtype: numpy.ndarray
        """
        return self.__data

    @data.setter
    def data(self, data):
        """
        Set the data for the audio stimulus directly. This function will add any required silence
        as a side-effect. Sub-classes of AudioStim should use this setter.

        :param numpy.ndarray data: The raw audio signal data representing this stimulus.
        """

        # If the user provided an attenuator, attenuate the signal
        if self.__attenuator is not None:
            data = self.__attenuator.attenuate(data, self.__frequency)

        data = self._add_silence(data)

        # Multiply the signal by the intensity factor
        data = data * self.__intensity

        self.__data = data

        # Perform limit check on data, make sure we are not exceeding
        if data.max() > self.__max_value:
            raise ValueError("Audio stimulus value exceeded max level!")

        if data.min() < self.__min_value:
            raise ValueError("Audio stimulus value lower than min level!")

    def data_generator(self):
        """
        Return a generator that yields the data member when next is called on it. Simply provides another interface to
        the same data stored in the data member.

        :return: A generator that yields an array containing the sample data.
        """
        while True:
            self.num_samples_generated = self.num_samples_generated + self.data.shape[0]
            self.trigger_next_callback(message_data=self.event_message, num_samples=self.data.shape[0])

            yield SampleChunk(data=self.data, producer_id=self.producer_id)

class MovingGratingsStim(VisualStim):
    """
       The SinStim class provides a simple interface for generating sinusoidal audio stimulus data
       appropriate for feeding directly as voltage signals to a DAQ for playback. It allows parameterization
       of the sinusoid as well as attenuation by a custom attenuation object.
    """

    def __init__(self, calibration_file=None,spatial_frequency=0,velocity=0):

        # Initiatialize the base class members
        super(MovingGratingsStim, self).__init__(calibration_file=calibration_file)

        self.__spatial_frequency = spatial_frequency
        self.__velocity = velocity

        # Add class specific parameters to the event message that is sent to functions in next_event_callbacks from the
        # base class generator.
        self.event_message["spatial_frequency"] = spatial_frequency
        self.event_message["velocity"] = velocity

        self.data = self._generate_data()

    @property
    def amplitude(self):
        """
        Get the amplitude of the sin signal.

        :return: The amplitude of the sin signal.
        :rtype: float
        """
        return self.__amplitude

    @amplitude.setter
    def amplitude(self, amplitude):
        """
        Set the amplitude of the sin signal.

        :param float amplitude: Set the amplitude of the sin signal.
        """
        self.__amplitude = amplitude
        self.data = self._generate_data()

    @property
    def phase(self):
        """
        Get the phase of the sin, in radians.

        :return: The phase of the sin, in radians.
        :rtype: float
        """
        return self.__phase

    @phase.setter
    def phase(self, phase):
        """
        Set the phase of the sin, in radians.

        :param float phase: The phase of the sin, in radians.
        """
        self.__phase = phase
        self.data = self._generate_data()

    def _generate_data(self):
        """
        Generate the sin sample data according to the parameters. Also attenuatte the signal if an attenuator
        is provided.

        :return: The sin signal data, ready to be passed to the DAQ as voltage signals.
        :rtype: numpy.ndarray
        """
        T = np.linspace(0.0, float(self.duration) / 1000.0, int((float(self.sample_rate) / 1000.0) * self.duration))

        # Generate the samples of the sin wave with specified amplitude, frequency, and phase.
        data = self.amplitude * np.sin(2 * np.pi * self.frequency * T + self.phase)

        return data


class SquareWaveStim(AudioStim):
    """
       The SquareWaveStim class provides a simple interface for generating square wave audio stimulus data
       appropriate for feeding directly as samples for sound card playback. It allows parameterization
       of the square wave as well as attenuation scaling.
    """

    def __init__(self, frequency, duty_cycle, amplitude, sample_rate, duration, intensity=1.0, pre_silence=0,
                 post_silence=0, attenuator=None, next_event_callbacks=None):

        # Initiatialize the base class members
        super(SquareWaveStim, self).__init__(sample_rate=sample_rate, duration=duration, intensity=intensity,
                                      pre_silence=pre_silence, post_silence=post_silence, attenuator=attenuator,
                                      frequency=frequency, next_event_callbacks=next_event_callbacks)

        self.__duty_cycle = duty_cycle
        self.__amplitude = amplitude

        # Add class specific parameters to the event message that is sent to functions in next_event_callbacks from the
        # base class generator.
        self.event_message["duty_cycle"] = duty_cycle
        self.event_message["amplitude"] = amplitude

        self.data = self._generate_data()

    @property
    def amplitude(self):
        """
        Get the amplitude of the sin signal.

        :return: The amplitude of the sin signal.
        :rtype: float
        """
        return self.__amplitude

    @amplitude.setter
    def amplitude(self, amplitude):
        """
        Set the amplitude of the sin signal.

        :param float amplitude: Set the amplitude of the sin signal.
        """
        self.__amplitude = amplitude
        self.data = self._generate_data()

    @property
    def duty_cycle(self):
        """
        Get the duty cycle of the signal, between 0 and 1.

        :return: The duty cycle of the signal, between 0 and 1.
        :rtype: float
        """
        return self.__duty_cycle

    @duty_cycle.setter
    def phase(self, duty_cycle):
        """
        Set the duty cyclce of the signal.

        :param float duty_cycle: The duty cycle, between 0 and 1.
        """
        self.__duty_cycle = duty_cycle
        self.data = self._generate_data()

    def _generate_data(self):
        """
        Generate the sin sample data according to the parameters. Also attenuatte the signal if an attenuator
        is provided.

        :return: The sin signal data, ready to be passed to the DAQ as voltage signals.
        :rtype: numpy.ndarray
        """
        T = np.linspace(0.0, float(self.duration) / 1000.0, int((float(self.sample_rate) / 1000.0) * self.duration))

        # Generate the samples of the sin wave with specified amplitude, frequency, and phase.
        data = self.amplitude * signal.square(T * 2 * np.pi * self.frequency, duty=self.duty_cycle)

        return data


class MATFileStim(AudioStim):
    """A class to encapsulate stimulus data that has been pre-generated and stored as MATLAB MAT files. The lab has a
    significant number of pre-generated audio stimulus patterns stored as MAT files. This class allows
    loading of these data files and playing them through the DAQ."""

    def __init__(self, filename, frequency, sample_rate, intensity=1.0, pre_silence=0, post_silence=0, attenuator=None,
                 next_event_callbacks=None):

        # Initiatialize the base class members
        super(MATFileStim, self).__init__(sample_rate=sample_rate, duration=None, intensity=intensity,
                                          pre_silence=pre_silence, post_silence=post_silence, attenuator=attenuator,
                                          frequency=frequency, next_event_callbacks=next_event_callbacks)

        self.__filename = filename

        # Add class specific parameters to the event message that is sent to functions in next_event_callbacks from the
        # base class generator.
        self.event_message["stim_filename"] = filename

        self.data = self._generate_data()

    @property
    def filename(self):
        """
        Get the filename that stored the audio data.

        :return: The filename that stored the audio data.
        :rtype: str
        """
        return self.__filename

    @filename.setter
    def filename(self, filename):
        """
        Set the filename and load the data.

        :param str filename: The name of the file that stores the audio stimulus data.
        """
        self.__filename = filename
        self.data = self._generate_data()

    def _generate_data(self):
        """
        Load the sample data from the file with path stored in __filename.

        :return: The audio stimulus data, ready to be passed to the DAQ as voltage signals.
        :rtype: numpy.ndarray
        """
        try:
            data = scipy.io.loadmat(self.__filename, variable_names=['stim'], squeeze_me=True)
            data = data['stim']

            return data
        except NotImplementedError as e:
            # This exception indicates that this is an HDF5 file and not an old type MAT file
            h5_file = h5py.File(self.__filename + '.mat', 'r')
            data = np.squeeze(h5_file['stim'])

            return data


class AudioStimPlaylist(SignalProducer):
    """A simple class that provides a generator for a sequence of AudioStim objects."""
    def __init__(self, stims, shuffle_playback=False, next_event_callbacks=None):

        # Attach event next callbacks to this object, since it is a signal producer
        super(AudioStimPlaylist, self).__init__(next_event_callbacks)

        self._stims = stims
        self.shuffle_playback = shuffle_playback

        # We need to create a dictionary that describes the state of stimulus playlist
        self.event_message = {"name" : "AudioStimulusPlaylist",
                              "stimuli" : [stim.event_message for stim in stims],
                              "shuffle_playback" : shuffle_playback}

        # If we want to shuffle things, get a random permutation.
        if (self.shuffle_playback):
            self.random_seed = int(time.time())

    """Lets make the class iterable since it is just a wrapper around a list of stimuli."""
    def __iter__(self):
        return iter(self._stims)

    @classmethod
    def fromfilename(cls, filename, shuffle_playback=False, attenuator=None, next_event_callbacks=None):

        def check_for_field(d, field_name):
            if field_name not in d:
                raise ValueError("Could not find column named {} in playlist, check format.".format(field_name))

        def parse_list(x):
            if isinstance(x, str):
                return x.replace('[','').replace(']','').split()
            else:
                return [x]

        # Get the root directory of this file
        local_dir = os.path.dirname(filename) + '/'

        # Read the playlist file
        data = pd.read_table(filename, sep="\t")

        # Convert all column names to lower case.
        data.columns = map(str.lower, data.columns)

        # Take only the first word of column names, no spaces allowed
        data.columns = map(lambda x: str.split(x)[0], data.columns)

        # Make sure we have the nescessary fields
        check_fields = ["stimfilename", "freq", "rate", "silencepre", "silencepost", "intensity"]
        for field in check_fields:
            check_for_field(data, field)

        # Get the stimulus filenames and load each one into a stimulus object
        row = 0
        stims = []
        for stim_string in data['stimfilename']:
            # Each stim_string field should be a semicolon separated list, each element should be a channel.
            chan_names = stim_string.split(';')

            def throw_error(msg):
                return ValueError("Error parsing playlist('{}') on line {}: {}".format(filename, row+2, msg))

            # Now, parse the parameter fields to make sure they have the correct number of fields.
            try:
                frequencies = list(map(float, parse_list(data["freq"][row])))
            except Exception as ex:
                raise throw_error("Couldn't parse frequencies!") from ex

            try:
                intensities = list(map(float, parse_list(data["intensity"][row])))
            except Exception as ex:
                raise throw_error("Couldn't parse intensities!") from ex

            # Make sure the sizes of the lists of parameters match the size of channels.
            if len(frequencies) != len(chan_names):
                raise throw_error("Number of frequencies is not equal to number of channels.")
            if len(intensities) != len(chan_names):
                raise throw_error("Number of intensities is not equal to number of channels.")

            # Load each channel's stimulus
            chans = []
            chan_idx = 0
            for chan_name in chan_names:
                if chan_name.lower() == "optooff" or chan_name.strip() == "":
                    chan = ConstantSignal(0.0)
                elif chan_name.lower() == "optoon":
                    chan = ConstantSignal(5.0)
                else:
                    if frequencies[chan_idx] == -1:
                        atten = None
                    else:
                        atten = attenuator

                    chan = MATFileStim(filename=local_dir + chan_name,
                                       frequency=frequencies[chan_idx],
                                       sample_rate=data["rate"][row], intensity=intensities[chan_idx],
                                       pre_silence=data["silencepre"][row],
                                       post_silence=data["silencepost"][row],
                                       attenuator=atten, next_event_callbacks=next_event_callbacks)

                chans.append(chan)
                chan_idx = chan_idx + 1

            # Get the maximum duration of all the channel's stimuli
            max_stim_len = max([next(chan.data_generator()).data.shape[0] for chan in chans])

            # Make sure we resize all the ConstantSignal's to be as long as the maximum stim
            # size, this will make data loading much more efficient since their generators will
            # not need to yield a single sample many times for one chunk of data.
            for i in range(len(chans)):
                if isinstance(chans[i], ConstantSignal):
                    chans[i] = ConstantSignal(chans[i].constant, num_samples=max_stim_len)

            # Combine these stimuli into one analog signal with a channel for each.
            mixed_stim = MixedSignal(chans)

            # FIXME: This really isn't clean. I wan't to mark each MixedStim by its position in the playlist. However,
            # this shouldn't be stored on the MixedSignal because it has no idea what playlists are really.
            mixed_stim.event_message['stim_playlist_idx'] = row

            # Append to playlist
            stims.append(mixed_stim)

            # Go to the next row
            row = row + 1

        return cls(stims, shuffle_playback)

    def data_generator(self):
        """
        Return a generator that yields each AudioStim in the playlist in succession. If shuffle_playback is set to true
        then we will get a non-repeating randomized sequence of all stimuli, then they will be shuffled, and the process
        repeated.
        :return: A generator that yields an array containing the sample data.
        """

        stim_idx = 0

        # Intitalize data generators for these _stims in the play list
        data_gens = [stim.data_generator() for stim in self._stims]

        # Store a local copy playlist state objects.
        shuffle_playback = self.shuffle_playback

        if shuffle_playback:
            rng = np.random.RandomState()
            rng.seed(self.random_seed)
            playback_order = rng.permutation(len(self._stims))
        else:
            playback_order = np.arange(len(self._stims))

        # Now, go through the list one at a time, call next on each one of their generators
        while True:

            play_idx = playback_order[stim_idx]

            sample_chunk_obj = next(data_gens[play_idx])

            data = sample_chunk_obj.data

            # We are about to yield, send an event to our callbacks
            self.trigger_next_callback(message_data=self.event_message, num_samples=data.shape[0])

            yield sample_chunk_obj

            stim_idx = stim_idx + 1

            # If we are at the end, then either go back to beginning or reshuffle
            if(stim_idx == len(playback_order)):
                stim_idx = 0

                if(shuffle_playback):
                    playback_order = rng.permutation(len(playback_order))
